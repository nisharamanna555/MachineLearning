{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77807dbe-22b1-4fdc-9e30-729b1bbf93d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb448029-0ea0-4c1f-878b-33309dc36003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Querylength</th>\n",
       "      <th>domain_token_count</th>\n",
       "      <th>path_token_count</th>\n",
       "      <th>avgdomaintokenlen</th>\n",
       "      <th>longdomaintokenlen</th>\n",
       "      <th>avgpathtokenlen</th>\n",
       "      <th>tld</th>\n",
       "      <th>charcompvowels</th>\n",
       "      <th>charcompace</th>\n",
       "      <th>ldl_url</th>\n",
       "      <th>...</th>\n",
       "      <th>SymbolCount_FileName</th>\n",
       "      <th>SymbolCount_Extension</th>\n",
       "      <th>SymbolCount_Afterpath</th>\n",
       "      <th>Entropy_URL</th>\n",
       "      <th>Entropy_Domain</th>\n",
       "      <th>Entropy_DirectoryName</th>\n",
       "      <th>Entropy_Filename</th>\n",
       "      <th>Entropy_Extension</th>\n",
       "      <th>Entropy_Afterpath</th>\n",
       "      <th>URL_Type_obf_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.726298</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.894886</td>\n",
       "      <td>0.850608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.859793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.695049</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.801880</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.640130</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.663210</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>14</td>\n",
       "      <td>7.333334</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.681307</td>\n",
       "      <td>0.784493</td>\n",
       "      <td>0.814725</td>\n",
       "      <td>0.804526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>Defacement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
       "0            0                   4                 5                5.5   \n",
       "1            0                   4                 5                5.5   \n",
       "2            0                   4                 5                5.5   \n",
       "3            0                   4                12                5.5   \n",
       "4            0                   4                 6                5.5   \n",
       "\n",
       "   longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
       "0                  14         4.400000    4               8            3   \n",
       "1                  14         6.000000    4              12            4   \n",
       "2                  14         5.800000    4              12            5   \n",
       "3                  14         5.500000    4              32           16   \n",
       "4                  14         7.333334    4              18           11   \n",
       "\n",
       "   ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
       "0        0  ...                     1                      0   \n",
       "1        0  ...                     0                      0   \n",
       "2        0  ...                     0                      0   \n",
       "3        0  ...                     0                      0   \n",
       "4        0  ...                     0                      0   \n",
       "\n",
       "   SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  Entropy_DirectoryName  \\\n",
       "0                     -1     0.726298        0.784493               0.894886   \n",
       "1                     -1     0.688635        0.784493               0.814725   \n",
       "2                     -1     0.695049        0.784493               0.814725   \n",
       "3                     -1     0.640130        0.784493               0.814725   \n",
       "4                     -1     0.681307        0.784493               0.814725   \n",
       "\n",
       "   Entropy_Filename  Entropy_Extension  Entropy_Afterpath  URL_Type_obf_Type  \n",
       "0          0.850608                NaN               -1.0         Defacement  \n",
       "1          0.859793                0.0               -1.0         Defacement  \n",
       "2          0.801880                0.0               -1.0         Defacement  \n",
       "3          0.663210                0.0               -1.0         Defacement  \n",
       "4          0.804526                0.0               -1.0         Defacement  \n",
       "\n",
       "[5 rows x 80 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fetch the PhishingVSBenignURL dataset\n",
    "file_path = '/Users/nisha/Desktop/spring2024/MachineLearning/DataSetForPhishingVSBenignUrl.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22401bb0-765e-4d7a-9c56-7f2d7ec7beaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Querylength  domain_token_count  path_token_count  avgdomaintokenlen  \\\n",
      "0            0                   4                 5                5.5   \n",
      "1            0                   4                 5                5.5   \n",
      "2            0                   4                 5                5.5   \n",
      "3            0                   4                12                5.5   \n",
      "4            0                   4                 6                5.5   \n",
      "\n",
      "   longdomaintokenlen  avgpathtokenlen  tld  charcompvowels  charcompace  \\\n",
      "0                  14         4.400000    4               8            3   \n",
      "1                  14         6.000000    4              12            4   \n",
      "2                  14         5.800000    4              12            5   \n",
      "3                  14         5.500000    4              32           16   \n",
      "4                  14         7.333334    4              18           11   \n",
      "\n",
      "   ldl_url  ...  SymbolCount_FileName  SymbolCount_Extension  \\\n",
      "0        0  ...                     1                      0   \n",
      "1        0  ...                     0                      0   \n",
      "2        0  ...                     0                      0   \n",
      "3        0  ...                     0                      0   \n",
      "4        0  ...                     0                      0   \n",
      "\n",
      "   SymbolCount_Afterpath  Entropy_URL  Entropy_Domain  Entropy_DirectoryName  \\\n",
      "0                     -1     0.726298        0.784493               0.894886   \n",
      "1                     -1     0.688635        0.784493               0.814725   \n",
      "2                     -1     0.695049        0.784493               0.814725   \n",
      "3                     -1     0.640130        0.784493               0.814725   \n",
      "4                     -1     0.681307        0.784493               0.814725   \n",
      "\n",
      "   Entropy_Filename  Entropy_Extension  Entropy_Afterpath  URL_Type_obf_Type  \n",
      "0          0.850608                NaN               -1.0                  0  \n",
      "1          0.859793                0.0               -1.0                  0  \n",
      "2          0.801880                0.0               -1.0                  0  \n",
      "3          0.663210                0.0               -1.0                  0  \n",
      "4          0.804526                0.0               -1.0                  0  \n",
      "\n",
      "[5 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# encode target column \"URL_Type_obf_Type\" using LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['URL_Type_obf_Type'])\n",
    "encoded_label = label_encoder.transform(df['URL_Type_obf_Type'])\n",
    "\n",
    "# replace old \"URL_Type_obf_Type\" with encoded_label\n",
    "feature_name = ['URL_Type_obf_Type']\n",
    "encoded_df = pd.DataFrame(encoded_label, columns=feature_name)\n",
    "df_encoded = pd.concat([df.drop('URL_Type_obf_Type', axis=1), encoded_df], axis=1)\n",
    "\n",
    "print(df_encoded.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "925d7f20-aee0-443f-bea5-7f60e25d47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y\n",
    "X = df_encoded.iloc[:, :-1]\n",
    "y = df_encoded.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a078b51-79ca-4ef8-87b0-1456c1b32008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are infinite values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# check for infinite values in X\n",
    "has_infinite = np.isinf(X)\n",
    "if np.any(has_infinite):\n",
    "    print(\"There are infinite values in the dataset.\")\n",
    "else:\n",
    "    print(\"There are no infinite values in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aced915e-98ca-43c3-99af-34a6d9efe43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with infinite values: [22422 23183 26468 27804 28029 28435 29619 29766 29944 29995]\n",
      "Columns with infinite values: [31]\n"
     ]
    }
   ],
   "source": [
    "# sklearn's DecisionTreeClassifier can't work w/ infinite values\n",
    "    # find exact location of infinite values\n",
    "rows_with_infinite = np.any(has_infinite, axis=1)\n",
    "cols_with_infinite = np.any(has_infinite, axis=0)\n",
    "\n",
    "print(f\"Rows with infinite values: {np.where(rows_with_infinite)[0]}\")\n",
    "print(f\"Columns with infinite values: {np.where(cols_with_infinite)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb9fa607-ade1-41df-a935-3ad410b69fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop samples w/ infinite values\n",
    "arr = np.where(rows_with_infinite)[0]\n",
    "for i in arr:\n",
    "    X.drop(i,inplace=True)\n",
    "    y.drop(i,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1507ba6a-fdf7-45f8-95cc-c330fae6e92c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are NaN values in the dataset.\n"
     ]
    }
   ],
   "source": [
    "# check for NaN values in X\n",
    "has_NaN = X.isnull()\n",
    "if np.any(has_NaN):\n",
    "    print(\"There are NaN values in the dataset.\")\n",
    "else:\n",
    "    print(\"There are no NaN values in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b9ac082-2341-4ff8-8ac5-5ea0e19f4260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with NaN values: [    0     1     2 ... 36672 36675 36677]\n",
      "Columns with NaN values: [ 5 65 66 75 76 77 78]\n"
     ]
    }
   ],
   "source": [
    "# sklearn's AdaBoostClassifier can't work w/ NaN values\n",
    "    # find exact location of NaN values\n",
    "rows_with_NaN = np.any(has_NaN, axis=1)\n",
    "cols_with_NaN = np.any(has_NaN, axis=0)\n",
    "\n",
    "print(f\"Rows with NaN values: {np.where(rows_with_NaN)[0]}\")\n",
    "print(f\"Columns with NaN values: {np.where(cols_with_NaN)[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa7e2f5f-b90e-4a7c-afb7-4a4e0e9aa982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute NaN values w/ mean\n",
    "    # there's too many rows w/ NaN values to drop\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eb5173e-ebff-4774-ac40-8d22169be1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into test and train data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f23304-d9ad-4e3a-8cc6-1b97cb22bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [1, 3, 6, 9, 12, 15, 18]\n",
    "criterion = ['gini', 'entropy']\n",
    "accuracy = []\n",
    "accuracy.append(['Impurity Measure', 'Depth', 'Train Accuracy', 'Test Accuracy'])\n",
    "\n",
    "for i in depths:\n",
    "    for j in criterion:\n",
    "        tree = DecisionTreeClassifier(criterion=j, max_depth=i)\n",
    "        tree.fit(X_train, y_train)\n",
    "        clf = AdaBoostClassifier(estimator=tree, algorithm='SAMME')\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred_train = clf.predict(X_train)\n",
    "        y_pred_test = clf.predict(X_test)\n",
    "        train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "        test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "        curr_acc = [j, i, train_accuracy, test_accuracy]\n",
    "        accuracy.append(curr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a5dbb5-dee9-491f-b1ff-5371fa6e326c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0      1               2              3\n",
      "0   Impurity Measure  Depth  Train Accuracy  Test Accuracy\n",
      "1               gini      1        0.720748        0.72139\n",
      "2            entropy      1        0.658242       0.656131\n",
      "3               gini      3        0.857206       0.857221\n",
      "4            entropy      3        0.850734       0.848365\n",
      "5               gini      6        0.970263       0.949046\n",
      "6            entropy      6         0.97074       0.949864\n",
      "7               gini      9             1.0       0.978202\n",
      "8            entropy      9             1.0       0.979155\n",
      "9               gini     12             1.0       0.980654\n",
      "10           entropy     12             1.0       0.980245\n",
      "11              gini     15             1.0       0.980109\n",
      "12           entropy     15             1.0       0.979428\n",
      "13              gini     18             1.0       0.980381\n",
      "14           entropy     18             1.0       0.978883\n"
     ]
    }
   ],
   "source": [
    "# compare results of DecisionTrees\n",
    "accuracy_df = pd.DataFrame(accuracy)\n",
    "print(accuracy_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34a34182-344c-4d7f-9632-2ce795f8464a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   0      1               2              3\n",
      "0   Impurity_Measure  Depth  Train_Accuracy  Test_Accuracy\n",
      "1               gini      1        0.377218       0.375511\n",
      "2            entropy      1        0.377218       0.375511\n",
      "3               gini      2          0.4945       0.493326\n",
      "4            entropy      2        0.495249       0.492373\n",
      "5               gini      3        0.484727        0.48243\n",
      "6            entropy      3        0.592712       0.586897\n",
      "7               gini      4        0.675192       0.671343\n",
      "8            entropy      4        0.669947       0.665622\n",
      "9               gini      5        0.730598       0.730046\n",
      "10           entropy      5        0.728214       0.728139\n",
      "11              gini      6        0.754163       0.753609\n",
      "12           entropy      6        0.737238       0.742713\n"
     ]
    }
   ],
   "source": [
    "# last weeks results:\n",
    "accuracy_str_lw = \"\"\"\n",
    "                   0      1               2              3\n",
    "0   Impurity_Measure  Depth  Train_Accuracy  Test_Accuracy\n",
    "1               gini      1        0.377218       0.375511\n",
    "2            entropy      1        0.377218       0.375511\n",
    "3               gini      2          0.4945       0.493326\n",
    "4            entropy      2        0.495249       0.492373\n",
    "5               gini      3        0.484727        0.48243\n",
    "6            entropy      3        0.592712       0.586897\n",
    "7               gini      4        0.675192       0.671343\n",
    "8            entropy      4        0.669947       0.665622\n",
    "9               gini      5        0.730598       0.730046\n",
    "10           entropy      5        0.728214       0.728139\n",
    "11              gini      6        0.754163       0.753609\n",
    "12           entropy      6        0.737238       0.742713\n",
    "\"\"\"\n",
    "accuracy_io_lw = StringIO(accuracy_str_lw)\n",
    "accuracy_df_lw = pd.read_csv(accuracy_io_lw, sep=\"\\s+\", engine='python')\n",
    "print(accuracy_df_lw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e3e286-f2cf-4d89-8d5f-17f9a2cb0c32",
   "metadata": {},
   "source": [
    "Using AdaBoostClassifier resulted in far better classifiers than achieved last week, when just using DecisionTreeClassifiers. At deeper depths, the AdaBoostClassifier was actually able to achieve perfect train accuracy and near perfect test accuracy. For both AdaBoostClassifier and just DecisionTreeClassifier, the impurity measure has far less impact on accuracy than depth."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
